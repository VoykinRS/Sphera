{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №2 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 1 ноября 2018, 06:00 \n",
    "**Штраф за опоздание:** -2 балла после 06:00 1 ноября, -4 балла после 06:00 8 ноября, -6 баллов после 06:00 15 ноября\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "Необходимо в slack создать таск в приватный чат:   \n",
    "/todo Фамилия Имя *ссылка на гитхаб* @alkhamush   \n",
    "Пример:   \n",
    "/todo Ксения Стройкова https://github.com/stroykova/spheremailru/stroykova_hw2.ipynb @alkhamush   \n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (4 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. В комментариях, где написано \"Что делает этот блок кода?\", ответьте на этот вопрос. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на wine и Speed Dating Data.\n",
    "\n",
    "###### Задание 2 (2 балла)\n",
    "Добиться скорости работы fit такой, чтобы она была медленнее sklearn не более чем в 10 раз. Скорость проверяем на  wine и Speed Dating Data. Для ускорения используем только numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 3 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw2.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None,\n",
    "                 sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return 1 - ((np.sum(np.hstack((l_c * l_c / l_s, r_c * r_c / r_s)),\n",
    "                            axis=1)) / (l_s[0] + r_s[0]))\n",
    "\n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return -np.sum(np.hstack((l_c * np.log2(l_c / l_s),\n",
    "                                  r_c * np.log2(r_c / r_s)),\n",
    "                                 axis=1))/(l_s[0] + r_s[0])\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return 1 - (np.max(l_c, axis=1) + np.max(r_c, axis=1)) / (l_s + r_s)\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:np.int(np.sqrt(n_feature))]\n",
    "\n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:np.int(np.log2(n_feature))]\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Сортируем значения признака х, y переставляется соответственоо\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = self.num_class\n",
    "        # Считаем минимальное количетство элементов выборки,\n",
    "        # которые попадут влево и вправо при делении\n",
    "        cut_size = np.int(self.min_samples_split / 2 - 1)\n",
    "        if cut_size == 0:\n",
    "            splitted_sorted_y = sorted_y\n",
    "        # Обрезаем массив, чтобы велево и вправо попало\n",
    "        # как минимум cut_size элементов\n",
    "        else:\n",
    "            splitted_sorted_y = sorted_y[cut_size:-cut_size]\n",
    "        # Нашли индексы элементов в которых изменился класс\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] !=\n",
    "                                splitted_sorted_y[1:])[0] + (cut_size + 1)\n",
    "        # Проверяем случай, если разделение невозможно\n",
    "        if len(r_border_ids) == 0:\n",
    "            return np.inf, None\n",
    "        # Считаем длины фрагментов массива на которых класс постоянен\n",
    "        eq_el_count = r_border_ids - np.append(np.array([cut_size]),\n",
    "                                               r_border_ids[:-1])\n",
    "        # Создаем пустую матрицу.\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        # Заполняем ее ставя значение 1 на позиции ij где i\n",
    "        # соответствует фрагменту где класс постоянен, а j номеру этого класса\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]),\n",
    "                     sorted_y[r_border_ids - 1]] = 1\n",
    "        # Умножаем нашу матрицу на  длинны блоков\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        # Добавляем количество элементов каждого класса находящейся\n",
    "        # в части sorted_y[:cut_size] в первый фрагмент\n",
    "        class_increments[0] = class_increments[0] + \\\n",
    "            np.bincount(sorted_y[:cut_size], minlength=class_number)\n",
    "        # в l_class_count лежит количество элементов каждого\n",
    "        # класса (столбцы) до выхода из фрагмента (строки)\n",
    "        # в r_class_count лежит количество элементов каждого\n",
    "        # класса (столбцы) после выхода из фрагмента (строки)\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)\n",
    "        r_class_count = np.bincount(sorted_y,\n",
    "                                    minlength=class_number) - l_class_count\n",
    "        # Считаем количество элементов каждого класса, в левом узле и\n",
    "        # в правом узле если мы будет делать разбиение после каждого фрагмента\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Выбирает индекс элемента, по которому разделяем\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        idx = np.argmin(gs)\n",
    "\n",
    "        # Возвращаем то что вычиается в формуле прироста информации и\n",
    "        # разделяющую границу\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        return gs[idx], (sorted_x[left_el_id-1] + sorted_x[left_el_id]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        classes = np.bincount(y, minlength=self.num_class) / x.shape[0]\n",
    "        moda = np.argmax(classes)\n",
    "        if pred_f == -1:\n",
    "            self.feature_importances_ = np.zeros(x.shape[1])\n",
    "            self.Size_fit = x.shape[0]\n",
    "        if self.max_depth is None:\n",
    "            self.max_depth = x.shape[0]\n",
    "        if ((depth > self.max_depth) or (x.shape[0] < self.min_samples_split)\n",
    "                or (classes[moda] > self.sufficient_share)):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, moda, classes)\n",
    "        else:\n",
    "            feature_ids = self.get_feature_ids(x.shape[1])\n",
    "            a = 1\n",
    "            best_ind = -1\n",
    "            best_thresh = -1\n",
    "            for i in feature_ids:\n",
    "                inp, thresh = self.__find_threshold(x[:, i], y)\n",
    "                if (inp < a):\n",
    "                    best_ind = i\n",
    "                    best_thresh = thresh\n",
    "                    a = inp\n",
    "            if (best_ind == -1):\n",
    "                self.tree[node_id] = (self.LEAF_TYPE, moda, classes)\n",
    "            else:\n",
    "                x_left, x_right, y_left, y_right =\\\n",
    "                    self.__div_samples(x, y, best_ind, best_thresh)\n",
    "                if ((x_left.shape[0] == 0) or (x_right.shape[0] == 0)):\n",
    "                    self.tree[node_id] = (self.LEAF_TYPE, moda, classes)\n",
    "                else:\n",
    "                    self.tree[node_id] = (self.NON_LEAF_TYPE,\n",
    "                                          best_ind, best_thresh)\n",
    "                    if self.G_function == self.__gini:\n",
    "                        b = 1 - np.sum(classes ** 2)\n",
    "                    elif self.G_function == self.__entropy:\n",
    "                        b = -np.sum(classes * np.log2(classes))\n",
    "                    else:\n",
    "                        b = 1 - np.max(classes)\n",
    "                    c = (b - a) * x.shape[0]\n",
    "                    self.feature_importances_[best_ind] += (c / self.Size_fit)\n",
    "                    new_id = 2 * node_id\n",
    "                    self.__fit_node(x_left, y_left, new_id + 1, depth + 1, 0)\n",
    "                    self.__fit_node(x_right, y_right, new_id + 2, depth + 1, 0)\n",
    "        # self.LEAF_TYPE\n",
    "        # self.NON_LEAF_TYPE\n",
    "\n",
    "        # self.tree\n",
    "        # self.max_depth\n",
    "        # self.sufficient_share\n",
    "        # self.min_samples_split\n",
    "\n",
    "        # self.get_feature_ids\n",
    "        # self.__find_threshold\n",
    "        # self.__div_samples\n",
    "        # self.__fit_node\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7835497835497836"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7835497835497836"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# тут делаете то же самое, что и на семинаре https://github.com/stroykova/spheremailru/blob/master/2018-02/lecture_04_trees/pract-speed-dating-trees-proc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%pycodestyle\n",
    "\n",
    "\n",
    "df = pd.read_csv('Speed Dating Data.csv', encoding='cp1251')\n",
    "\n",
    "\n",
    "def f(df):\n",
    "    df = df.iloc[:, :97]\n",
    "    df = df.drop(['id', 'idg', 'condtn', 'round', 'position', 'positin1',\n",
    "                 'order', 'partner', 'age_o', 'race_o', 'pf_o_att', 'pf_o_sin',\n",
    "                  'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'dec_o',\n",
    "                  'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o',\n",
    "                  'like_o', 'prob_o', 'met_o', 'field', 'undergra',\n",
    "                  'imprelig', 'imprace', 'from', 'zipcode', 'career', 'sports',\n",
    "                  'tvsports', 'exercise', 'dining', 'museums',\n",
    "                  'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv',\n",
    "                  'theater', 'movies', 'concerts', 'music', 'shopping',\n",
    "                  'yoga', 'expnum', 'wave'], axis=1)\n",
    "    df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(0)\n",
    "    df = pd.get_dummies(df, columns=['field_cd'],\n",
    "                        prefix='field_cd', prefix_sep='=')\n",
    "    df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',',\n",
    "                                                          '').astype(np.float)\n",
    "    df.loc[:, 'mn_sat'] = df.mn_sat.fillna(-999)\n",
    "    df.loc[:, 'tuition'] =\\\n",
    "        df.loc[:, 'tuition'].str.replace(',', '').astype(np.float)\n",
    "    df.loc[:, 'tuition'] = df.tuition.fillna(-999)\n",
    "    df.loc[:, 'income'] =\\\n",
    "        df.loc[:, 'income'].str.replace(',', '').astype(np.float)\n",
    "    df.loc[:, 'income'] = df.loc[:, 'income'].fillna(-999)\n",
    "    df = df.dropna(subset=['date'])\n",
    "    df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(0)\n",
    "    df = pd.get_dummies(df, columns=['career_c'],\n",
    "                        prefix='career_c', prefix_sep='=')\n",
    "    a = ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']\n",
    "    df.loc[:, 'temp_totalsum'] = df.loc[:, a].sum(axis=1)\n",
    "    df.loc[:, a] =\\\n",
    "        (df.loc[:, a].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "    a = ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']\n",
    "    df.loc[:, 'temp_totalsum'] = df.loc[:, a].sum(axis=1)\n",
    "    df.loc[:, a] =\\\n",
    "        (df.loc[:, a].T / df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "    df = df.drop(['temp_totalsum'], axis=1)\n",
    "    for i in [4, 5]:\n",
    "        feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i),\n",
    "                'intel{}_1'.format(i), 'fun{}_1'.format(i),\n",
    "                'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "    df = df.drop(feat, axis=1)\n",
    "    df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid'])\\\n",
    "                .drop(['gender'], axis=1).dropna()\n",
    "    df_female = df.query('gender == 0').drop_duplicates(subset=['iid'])\\\n",
    "                  .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1)\\\n",
    "                  .dropna()\n",
    "    df_female.columns = df_female.columns + '_f'\n",
    "    df_female = df_female.drop(['pid_f'], axis=1)\n",
    "    df_pair = df_male.join(df_female.set_index('iid_f'), on='pid', how='inner')\n",
    "    df_pair = df_pair.drop(['iid', 'pid'], axis=1)\n",
    "    X = df_pair.iloc[:, 1:].values\n",
    "    y = df_pair.iloc[:, 0].values\n",
    "    return X, y, df_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,A = f(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age</th>\n",
       "      <th>mn_sat</th>\n",
       "      <th>tuition</th>\n",
       "      <th>race</th>\n",
       "      <th>income</th>\n",
       "      <th>goal</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>career_c=8.0_f</th>\n",
       "      <th>career_c=9.0_f</th>\n",
       "      <th>career_c=10.0_f</th>\n",
       "      <th>career_c=11.0_f</th>\n",
       "      <th>career_c=12.0_f</th>\n",
       "      <th>career_c=13.0_f</th>\n",
       "      <th>career_c=14.0_f</th>\n",
       "      <th>career_c=15.0_f</th>\n",
       "      <th>career_c=16.0_f</th>\n",
       "      <th>career_c=17.0_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1871</th>\n",
       "      <td>0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>78193.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63351.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>0</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>1</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      match  int_corr  samerace   age  mn_sat  tuition  race   income  goal  \\\n",
       "1871      0      0.16         0  26.0  -999.0   -999.0   4.0  78193.0   1.0   \n",
       "1876      0      0.34         1  32.0  -999.0   -999.0   2.0  63351.0   1.0   \n",
       "1881      0      0.52         0  37.0  -999.0   -999.0   4.0   -999.0   1.0   \n",
       "1886      1      0.13         1  29.0  -999.0   -999.0   2.0   -999.0   1.0   \n",
       "1891      0      0.05         0  28.0  -999.0   -999.0   3.0   -999.0   1.0   \n",
       "\n",
       "      date       ...         career_c=8.0_f  career_c=9.0_f  career_c=10.0_f  \\\n",
       "1871   4.0       ...                      0               0                0   \n",
       "1876   3.0       ...                      0               0                0   \n",
       "1881   6.0       ...                      0               0                0   \n",
       "1886   5.0       ...                      0               0                0   \n",
       "1891   6.0       ...                      0               0                0   \n",
       "\n",
       "      career_c=11.0_f  career_c=12.0_f  career_c=13.0_f  career_c=14.0_f  \\\n",
       "1871                0                0                0                0   \n",
       "1876                0                0                0                0   \n",
       "1881                0                0                0                0   \n",
       "1886                0                0                0                0   \n",
       "1891                0                0                0                0   \n",
       "\n",
       "      career_c=15.0_f  career_c=16.0_f  career_c=17.0_f  \n",
       "1871                0                0                0  \n",
       "1876                0                0                0  \n",
       "1881                0                0                0  \n",
       "1886                0                0                0  \n",
       "1891                0                0                0  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 82.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 339 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5335978180014878"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4818181818181818"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sinc4_1      0.161597\n",
       "shar4_1      0.149219\n",
       "go_out_f     0.142204\n",
       "fun2_1_f     0.135497\n",
       "exphappy     0.122001\n",
       "sinc4_1_f    0.096291\n",
       "income_f     0.080326\n",
       "race_f       0.041148\n",
       "tuition_f    0.038617\n",
       "int_corr     0.033100\n",
       "dtype: float64"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = my_clf.feature_importances_ / np.sum(my_clf.feature_importances_)\n",
    "My_feature = pd.Series(data=data, index=A.columns[1:]) \n",
    "My_feature.sort_values(ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int_corr      0.070864\n",
       "tuition_f     0.034682\n",
       "age           0.033663\n",
       "shar1_1       0.032284\n",
       "shar2_1       0.029097\n",
       "date          0.028563\n",
       "intel1_1_f    0.026516\n",
       "attr2_1       0.026027\n",
       "attr3_1       0.025484\n",
       "income_f      0.022571\n",
       "dtype: float64"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Feature = pd.Series(data=clf.feature_importances_, index=A.columns[1:]) \n",
    "Feature.sort_values(ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_impurity_decrease': 0.001, 'max_features': 'log2', 'max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs=7) \n",
    "params = { \n",
    "\"max_features\": ['auto','sqrt','log2'], \n",
    "\"max_depth\": [i for i in range(1, 20)], \n",
    "\"min_impurity_decrease\": [i / 1000 for i in range(1, 20)] \n",
    "} \n",
    "A = RandomizedSearchCV(clf, \n",
    "param_distributions=params, n_iter=30) \n",
    "A.fit(X, y) \n",
    "print(A.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
